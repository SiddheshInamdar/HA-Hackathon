{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.003878,
     "end_time": "2020-09-06T15:51:58.434093",
     "exception": false,
     "start_time": "2020-09-06T15:51:58.430215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Some of the amazing work by the fellow kagglers that i explored:\n",
    "\n",
    "*** https://www.kaggle.com/cdeotte/xgb-fraud-with-magic-0-9600**\n",
    "\n",
    "*** https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575**\n",
    "\n",
    "*** https://www.kaggle.com/c/cat-in-the-dat-ii/discussion/140465**\n",
    "\n",
    "*** https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist (used this for CV with nnets)**\n",
    "\n",
    "***https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/175614**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.002346,
     "end_time": "2020-09-06T15:51:58.439538",
     "exception": false,
     "start_time": "2020-09-06T15:51:58.437192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "* **https://www.kaggle.com/gcspkmdr/lets-get-rid-of-the-patients-feature-engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.002347,
     "end_time": "2020-09-06T15:51:58.444491",
     "exception": false,
     "start_time": "2020-09-06T15:51:58.442144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Algorithms Used\n",
    "\n",
    "> **1. All variants have used the same features**\n",
    "\n",
    "> **2. Explicitly telling the classifier that a certain feature is categorical gave boost to performance**\n",
    "\n",
    "\n",
    "\n",
    "> * **LGBM Classifier**\n",
    "\n",
    "**https://www.kaggle.com/gcspkmdr/lets-get-rid-of-the-patients**\n",
    "\n",
    "> * **XGB Classifier**\n",
    " \n",
    "**https://www.kaggle.com/gcspkmdr/lets-get-rid-of-the-patients-xgboost**\n",
    "\n",
    "> * **CatBoost**\n",
    "\n",
    "**https://www.kaggle.com/gcspkmdr/lets-get-rid-of-the-patients-catboost**\n",
    "\n",
    "> * **Various NN architecture via DeepTables** (**https://github.com/DataCanvasIO/deeptables/blob/master/docs/source/models.md**)\n",
    "\n",
    "**https://www.kaggle.com/gcspkmdr/a-model-built-on-garbage-deeptables-pnn** \n",
    "\n",
    "**https://www.kaggle.com/gcspkmdr/a-model-built-on-garbage-deeptables-dcn**\n",
    "\n",
    "**https://www.kaggle.com/gcspkmdr/a-model-built-on-garbage-deeptables**\n",
    "\n",
    "**https://www.kaggle.com/gcspkmdr/a-model-built-on-garbage-deeptables-opnn**\n",
    "\n",
    "\n",
    "> **Findings:**\n",
    "\n",
    "> **1. LGBM is very slow. GPU usage didn't help much(Also you have to  build it every time you open the notebook)**\n",
    "\n",
    "> **2. GPU hurt the performance also in case of LGBM. The multi log loss didn't decrease to same level as compared to CPU**\n",
    "\n",
    "> **3. XGB also didn't sped up much with GPU**\n",
    "\n",
    "> **4. CatBoost was the best among gradient tree based methods**\n",
    "\n",
    "> **5. CatBoost was performed well in terms of performace and speed with GPU**\n",
    "\n",
    "> **6. NN architecture with the capabilty of converting tabular categorical features to emeddings performed the best**\n",
    "\n",
    "> **7. There was corelation between the validation loss and validationn accuracy. This was most likely because of the poor quality of dataset**\n",
    "\n",
    "\n",
    "> **Things to explore**\n",
    "\n",
    "> * RapidAI for feature enginering(Pandas dataframes are too slow. RapidAI uses GPU to speed up the proces)\n",
    "\n",
    "> * Dask Dataframes for feature engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.002503,
     "end_time": "2020-09-06T15:51:58.449624",
     "exception": false,
     "start_time": "2020-09-06T15:51:58.447121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensembling\n",
    "\n",
    "**https://www.kaggle.com/gcspkmdr/let-s-get-rid-of-the-patients-ensemble**\n",
    "\n",
    "2 X NN are used(DCN and PNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.002363,
     "end_time": "2020-09-06T15:51:58.454523",
     "exception": false,
     "start_time": "2020-09-06T15:51:58.452160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Adversarial Validation\n",
    "\n",
    "> * **For sanity check**\n",
    "\n",
    "**https://www.kaggle.com/gcspkmdr/adversarial-validation-on-garbage**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.002304,
     "end_time": "2020-09-06T15:51:58.459387",
     "exception": false,
     "start_time": "2020-09-06T15:51:58.457083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 4.314761,
   "end_time": "2020-09-06T15:51:58.570666",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-06T15:51:54.255905",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
